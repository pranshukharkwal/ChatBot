{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: pip: command not found\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pyjokes\n",
    "from keras.models import load_model\n",
    "import json\n",
    "import random\n",
    "import tensorflow as tf   \n",
    "import pandas as pd\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import convert\n",
    "import weather_forecast as wf    \n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wikipedia(sentence):\n",
    "    sentence = sentence.title()\n",
    "    tagged_sent = pos_tag(sentence.split())\n",
    "    pn = [word for word,pos in tagged_sent if pos == 'NNP']\n",
    "    final = \"\".join(pn)\n",
    "    return wikipedia.summary(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prayagraj\n",
      "{'date': '2021-01-20',\n",
      " 'day': {'humidity': None,\n",
      "         'narrative': None,\n",
      "         'phrases': None,\n",
      "         'precipitate': None,\n",
      "         'temperature': None,\n",
      "         'uv_description': None,\n",
      "         'wind_speed': None},\n",
      " 'night': {'humidity': 86,\n",
      "           'narrative': 'Generally clear. Hazy. Low 11ÂºC. Winds W and '\n",
      "                        'variable.',\n",
      "           'phrases': 'Clear',\n",
      "           'precipitate': 6,\n",
      "           'temperature': 11,\n",
      "           'uv_description': 'Low',\n",
      "           'wind_speed': 8},\n",
      " 'place': 'Prayagraj',\n",
      " 'time': '20:47:11'}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def get_weather(sentence):\n",
    "    sentence = sentence.title()\n",
    "    tagged_sent = pos_tag(sentence.split())\n",
    "    pn = [word for word,pos in tagged_sent if pos == 'NNP']\n",
    "    if \"Weather\" in pn:\n",
    "        pn.remove(\"Weather\")\n",
    "    final = \"\".join(pn)\n",
    "    print(final)\n",
    "    type(wf.forecast(place = final))\n",
    "print(get_weather('what is the weather of prayagraj'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(sentence, words, show_details=True):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s:\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(sentence, model , words , classes):\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.1\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>=ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    print(return_list)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(intent , qtype):\n",
    "    lisp = []\n",
    "    if qtype == 'type1':\n",
    "        data_file = open('database/intents1.json').read()\n",
    "        lisp = json.loads(data_file)[\"type1\"]\n",
    "    elif qtype == 'type2':\n",
    "        data_file = open('database/intents2.json').read()\n",
    "        lisp = json.loads(data_file)[\"type2\"]\n",
    "    elif qtype == 'type3':\n",
    "        data_file = open('database/intents3.json').read()\n",
    "        lisp = json.loads(data_file)[\"type3\"]\n",
    "        \n",
    "    for i in lisp:\n",
    "        if(i['tag']== intent):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(sentence , qtype):\n",
    "    no = qtype\n",
    "    model = load_model('models/model' + no + '.h5')\n",
    "    words = pickle.load(open('type' + no + '/words.pkl','rb'))\n",
    "    classes = pickle.load(open('type' + no + '/classes.pkl','rb'))\n",
    "    found_intent = predict_class(sentence , model , words , classes)[0]['intent']\n",
    "#     print(\"Intent is \" , found_intent)\n",
    "    return found_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(question):\n",
    "#     print(\"Finding the type\")\n",
    "    model = load_model('models/model.h5')\n",
    "    words = pickle.load(open('main_model/words.pkl','rb'))\n",
    "    classes = pickle.load(open('main_model/classes.pkl','rb'))\n",
    "    qtype = predict_class(question , model , words , classes)[0]['intent']\n",
    "#     print(\"\\nQuestion type is\" , qtype , end='\\n\\n')\n",
    "    if qtype == 'type1':\n",
    "        it = call_model(question , '1')\n",
    "    elif qtype == 'type2':\n",
    "        it = call_model(question , '2')\n",
    "    elif qtype == 'type3':\n",
    "        it = call_model(question , '3')\n",
    "    return (qtype, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(lisp):\n",
    "    data = {}\n",
    "    data['question'] = lisp\n",
    "    data['intent'] = []\n",
    "    data['types'] = []\n",
    "    for question in lisp:\n",
    "        print(question)\n",
    "        a = main(question)\n",
    "        data['intent'].append(a[1])\n",
    "        data['types'].append(a[0])\n",
    "        if a[1] == 'suggest_movie':\n",
    "            print('Response : Here is a movie suggestion' , convert.give_suggestion('movies'))\n",
    "        elif a[1] == 'suggest_song':\n",
    "            print('Response : Here is a song suggestion' , convert.give_suggestion('songs'))\n",
    "        elif a[1] == 'suggest_book':\n",
    "            print('Response : Here is a book suggestion' , convert.give_suggestion('books'))\n",
    "        elif a[1] == 'tell_joke':\n",
    "            print(\"Response : Here is a joke\" , pyjokes.get_joke('en'))\n",
    "        elif a[1] == 'get_info':\n",
    "            print(\"Response :\" , fetch_wikipedia(question))\n",
    "        else:\n",
    "            typeq = a[0]\n",
    "            intentq = a[1]\n",
    "            print(\"Response :\" , getResponse(intentq , typeq))\n",
    "        print()\n",
    "    data = pd.DataFrame(data)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngl you are truly amazing\n",
      "[{'intent': 'type1', 'probability': '1.0'}]\n",
      "[{'intent': 'greeting', 'probability': '0.9644849'}]\n",
      "Response : Hi there, how can I help?\n",
      "\n",
      "                    question    intent  types\n",
      "0  ngl you are truly amazing  greeting  type1\n"
     ]
    }
   ],
   "source": [
    "lisp = [\"ngl you are truly amazing\"]\n",
    "# lisp = [\"tell me about elon musk\" , \"suggest me a movie\" , \"tell me a joke\" , \"hello how are you\"]\n",
    "solve(lisp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
